{
    "collab_server" : "",
    "contents" : "---\ntitle: \"TTP 289 - Homework #2\"\noutput:\n  html_document: default\n  html_notebook: default\n---\n\n```{r echo = FALSE, results='hide', message=FALSE, warning=FALSE}\n#for manipulation\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(magrittr)\nlibrary(data.table)\n\n\n#for viz\n# library(formattable)\n# library(grid)\n# library(gridExtra) #plot muliple grobs\nlibrary(ggplot2)\n# library(RColorBrewer) #makes own color palettes\nlibrary(naniar) #Shows missing data \n# library(waffle) #pie chart alternative\n\n```\n\n\n\n##Problem 1: Crack the code\n**Provide a description for what each of the functions do:**\n\n The function below returns the magnitude of a number (using base 10). Function1 first checks if the input is an integer, if it is not the function ceases and returns and error message. Alternatively, if the input is an integer, the function calculates the magnitude of the input. It does this by dividing the input by increasing powers of 10 inside a 'while loop'. Each iteration the input is divided by 10^a, \"a\" is a variable which increases with the iteration count. The number of completed iterations is counted until the condition is 'while loop' condition is met. See annotated code chunk below for a line-by-line explination.\n\n```{r}\nfunction1 <- function(n) {\n  if(is.integer(n)==FALSE) { #checks if input is an integer\n    print('This function requires an integer input') #printed warnign message if input is not an integer\n    break #stops the continutation of function1\n  }\n  \n  a <- 1 #this and the next three lines initialize computation/counting variables\n  out <- 0\n  x <- 0\n  c <- 2\n\n  while(c>1) { #initates while loop and sets exit criteria \n    c <- n/(10^a) #divides inpute by increasing powers of 10 \n    a <- a+1 #increases power \n    out <- out+1 #counts number of iterations or magnitudes\n  }\n  return(out)\n}\n\n```\n\n\nFunction2 counts the number of odd and even number of digits in an integer input ((excluding zero) and returns if there are more odd digits than even in the form of a \"TRUE\". In the case that a digit is zero, the fuction hits a breakpoint and exits out of the caluclation loop. The counting of even and odd digits occurs by digit. A whileloop divides the input by incresing powers of 10 and floor rounds the resulting value, the result of which is an integer with either an even, odd, or zero in the ones digit. Counting is perfomed by an \"if else if\" chunk of code. If the digit being counted is a zero then the counter is exited.If not zero, seperate odd and even capture value. The counting operation continues to until the whileloop condition is met.See annotated code chunk below for a line-by-line explination.\n\n```{r}\nfunction2 <- function(n) {\n  if(is.integer(n)==FALSE) { #checks if input is an integer\n    print('This function requires an integer input')#printed warnign message if input is not an integer\n    break #stops the continutation of function1\n  }\n  \n  n <- abs(n) #this and the next three lines initialize computation/counting variables\n  a <- 2\n  x <- 0\n  e <- 0\n  o <- 0\n  \n  while(a>1) { #initiates whileloop and sets exit condition (that all digits have been looped through)\n    a <- n/(10^x) #performs same magnitude division calcualtion as in function1\n    b <- floor(a)%%2 #floor rounds (a) and assigns the remainder when divided by 2 to (b)\n    x <- x+1 #acts as a counter, in this case the power of 10 which meets while loop condition\n\n    if(floor(a)%%10==0) { #checks if the remiander when divisible by 10 is zero, i.e. the digit is zero and ceases running counter \n      break\n      \n    } else if(b==0 & floor(a)%%10 != 10) {\n      e <- e+1 #acts as a counter, in this case the number of even digits in the input\n    } else if(b==1) {\n      o <- o+1 #acts as a counter, in this case the number of odd digits in the input\n    } \n  }\n  return(o>e) #retruns trua/false given number of odd and even digits in input\n}\n```\n\n**Please write a function that takes the month, day of the month, and year and returns the day of the week (1-7). In other words, please complete the following:**\n\n```{r}\ndayofWeek = function(m,d,y) {\n  if (y<1582) {\n    return(\"Date entered is before start of Gregorian Caldendar!!\")\n    break\n  }\n  if (m>12) {\n    return(\"Check yourself before you wreck yourself, fix your month input!!\")\n    break\n  }\n  \n  calender = data.table(month = seq(1,12,1), \n                          day.norm = c(31, 28, 31,30,31,30, 31, 31, 30, 31, 30, 31), \n                          day.leap = c(31, 29, 31,30,31,30, 31, 31, 30, 31, 30, 31))\n  day = data.table(num = seq(1,7,1), \n                   day = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\" ))\n  \n  leap.indx = c(seq(1584, 2016, by= 4),seq(2020, 20200, by= 4))\n  leap.indx = leap.indx[-which(leap.indx %% 400 != 0 & leap.indx %% 100 == 0 )]\n  \n  if (y == 1900) {\n    i = ifelse( 1900 %in% leap.indx, 3, 2)\n    if (d>calender[m,..i]) {\n        return(\"Check yourself before you wreck yourself, fix your day input!!!\")\n        break\n      }\n    day.tot = (sum(calender[c(1:m),..i]) - calender[m,..i]) + d \n    return( paste(\"Yo! That day is a\", (day$day[sum(day.tot %% 7)+1])   , \"!\", day.tot, \"days away.\") )\n    break\n  }\n  \n  for (n in 1:(y-1900+1)) {\n      last = max(1:(y-1900+1))\n      i = ifelse( (n+1899) %in% leap.indx, 3, 2)\n      if (d>calender[m,..i]) {\n        return(\"Check yourself before you wreck yourself, fix your day input!!\")\n        break\n      }\n      if (n == 1) {\n        day.tot = 365\n      } else if (n == last) {\n        day.tot = day.tot + (sum(calender[c(1:m),..i])-calender[m,..i]) + d\n      } else {\n        day.tot = day.tot + sum(calender[,..i])\n      }\n  }\n  return(paste(\"Yo! That day is a\", day$day[sum(day.tot %% 7)+1], \"!\"))\n}\n```\n\n```{r}\ndayofWeek(1,1, 1973)\n```\n```{r}\ndayofWeek(5,13,2167)\n```\n```{r}\ndayofWeek(5,98,2019)\n```\n\n```{r}\ndayofWeek(13,1,2019)\n```\n\n##Problem 2: What's it mean?\n\n###Wages\n\n**Provide the interpretation for education and age effect on overall wages.**\n\nWith each additional year of education, one makes an additional 2,268. dollars. \nWith each additional year of age, one makes an additional ~250 dollars.\n\n**What are the base levels for each of the dummy/categorical variables? (Don't forget about the interaction term!). Provide the interpretation for the sex and race variables.**\n\nThere are in effect two types of dummy variables at play in this model. First, there are four dummy variables which effect the earnings intercept and three dummy variables which effect the slope of earnings given an increase in age. \n\nThe dummy variables which change the intercept are sex (male), black, Hispanic, and other. The base level for sex is being female and the base level for race is being white. Interaction variables are formed between age and the races black, Hispanic, and other.  If you're a man, you make 17k more than women. When compared the base level of being white, blacks, Hispanics and other, systematically make 7.6k, 18k, and 16k less, respectively. Likewise, when compared to the unit increase in earnings per age increase for whites ($250), blacks make 81 more dollars on top of that base rate - Hispanics and other make an additional 286 and 249 dollars, respectively.\n\n\n**Provide the interpretation for the race-age interaction variables. What conclusion can we say about the difference in effect of age for each of the races? If the base level were changed would these conclusions still hold?**   \n\nThe race and age interaction variables are a little muddy. First, none of these variables can be considered as significant. Second, the standard error for most of these variables are large enough to capture zero, meaning there is a reasonable probability that there is no effect from these interaction variables. Given their lack of significance and their relatively large standard errors, one should be causes when including these variables in the model. \n\n**In providing these conclusions to the model, we have made some assumptions about the validity of the model. What additional considerations should we have made before making these interpretations?**\n\nThere are a few things that should be noted. As, mentioned above, the current model includes many insignificant variables.  A simpler model can potentially perform better and without the additional mathematical complexity when including the interaction terms.  \n\n###Video Game Sales\n\n**Provide the interpretation for the score and count variables. Do these values all make sense? Is there some qualitative interpretation for counterintuitive results?**\n\nCritic Score - With each increase in one critical score, global sales increases .027 million. \n\nCritic Count - With each increase in one critic count, global sales increases .019 million. \n\nUser Score - With each increase in one User score, global sales increases .01 million. \n\nUser Count - With each increase in one User count, global sales increases .001 million.  \n\nThe impact of user score on global sales is counterintuitive. If fans like a platform and in turn rate it higher one would think that there would be higher global sales.\n\n\n**Which platforms are more popular than the 3DS? Less popular?**\n\nThe 3DS is the base level platform in the model, all the other platforms are dummy variables which either raised or lower the intercept of the sales. If a platform factor is negative in the summary table, that platform performed worse than the base level (3DS) in global sells. Alternatively, if the value is positive, it performed better than the 3DS. Some platforms which performed better were the DS, the PlayStation original, the PS2, and the Wii. Some platforms which performed worse were the Xbox, the Xbone, and PC.\n\n**Any other observations? If you had the full dataset, what other things might you look at or consider?**\n\nOvertime there are more choices available for the consumer to make, not only are there new models for given platforms but one can still choose older models. This may be tied to the observation that the \"newer\" models per a given platform worse ie Ps versus PS4. Potentially confounding variables which were not included in this model but may be significant are each platform release date and the number of games available at the time of release.\n\n\n##Problem 3: Revisiting Doris\n\nLet's revisit the previous homework question on my car Doris and apply newly learned regression analysis\ntechniques. Use the \"fuelingData_cleaned.csv\" dataset.\n```{r}\nfuel.data = read.csv(\"./Data/fuelingData_clean.csv\", header = TRUE) \n```\n\n```{r}\nstr(fuel.data)\n```\n\n```{r}\nfuel.data$OdoFault = as.factor(fuel.data$OdoFault) \n```\n\n```{r}\nhead(fuel.data)\n```\n\n```{r}\nsummary(fuel.data)\n```\n\n```{r ridge, fig.height = 4, fig.width = 4}\n#checking to see if there is missing data\nvis_miss(fuel.data)\n```\n\n##Problem 2:Conduct a linear regression model regressing miles on gasoline and provide the results of the regression table, do not omit data. Please interpret the results provided by the regression table.##Problem 2:\n\nA:  Regressing miles on gasoline consumed using the unfiltered data produces a poor model. The intercept of the model is 162, meaning if the vehicle has no gas or if no gas is consumed the last time it was filled will travel 162 miles. The slope of the regression is 6.43 miles for every 1 gallon consumed. Both number  seems off. In most cases the intercept is meaningless and can be considered mathematical construct produced by the model; however, the produced intercept seems exceptionally large. In addition, the slope or mpg of the vehicle is suspiciously low ~6.5 miles per gallon.\n\nThe slope of the regression also has a large p-value, so large that it is insignificant even at the 10% level. The R2 value is very low meaning the model as poor explanatory power.\n\n\n```{r}\nln.model.1 = lm(Miles~Gallons, data = fuel.data)\n```\n\n```{r}\nsummary(ln.model.1)\n```\n\n```{r}\nggplot(fuel.data) +\n  geom_point(aes(Gallons, Miles, color = as.factor(OdoFault))) +\n  geom_line(aes(Gallons, ln.model.1$fitted.values)) +\n  labs(y = \"Residuals\", title = \"Residual plot for Miles reressed on Gallons (unfiltered)\", color = \"Odometer Fault\") +\n  geom_hline(yintercept = 0, alpha = .2) +\n theme_classic() \n```\n\n**What are five possible sources of error in the regression?**\n\nConfounding variables - working/faulty odometer.\n\nHeteroscedastic/non-constant variance.\n\nFalse data i.e. garbage in-garbage out.\n\nSkewed data. \n\n**Provide a graph of the residuals, how is the model fit? For data points where the odometer is faulty, color the points red.**\n\nAs seen in the residual plot below. The model is a poor fit. There is homoscedasticity in the residuals, the variance is not constant, and there is substantial clustering of data. The points colored blue are faulty and severely weigh down the regression.\n\n```{r}\nggplot(fuel.data) +\n  geom_point(aes(Gallons, ln.model.1$residuals, color = as.factor(OdoFault))) +\n  labs(y = \"Residuals\", title = \"Residual plot for Miles reressed on Gallons (unfiltered)\", color = \"Odometer Fault\") +\n  geom_hline(yintercept = 0, alpha = .2) +\n theme_classic() \n```\n\n**Plot both the leverage and Cook's distance for the model, color points where the odometer is faulty red. Provide a qualitative interpretation of these plots.**\n\n```{r}\ndf = cbind.data.frame(fuel.data$Gallons,\n                      fuel.data$Miles,\n                      fuel.data$OdoFault,\n                      hat(model.matrix(ln.model.1)), \n                      cooks.distance(ln.model.1))\n\ncolnames(df) = c(\"Gallons\",\n                 \"Miles\",\n                 \"Fault\",\n                 \"Leverage\", \n                 \"Cooks\")\n\n```\n\n```{r}\nggplot(df) +\n  geom_point(aes(Leverage, ln.model.1$residuals, color = Fault)) +\n  geom_hline(yintercept = 0, alpha = .2, linetype = \"dashed\") +\n  geom_vline(xintercept = (2/nrow(df)), alpha = .2, linetype = \"dashed\") +\n  labs(y = \"Residuals\", title = \"Leverage Plot with Residuals\") +\n  theme_classic()\n\nggplot(df) +\n  geom_point(aes(as.numeric(row.names(df)), Leverage, color = Fault)) +\n  labs(x = \"Indices\", y = \"Leverage\", title = \"Leverage Plot with Date Indices\") +\n  theme_classic()\n```\n\n\n```{r}\nggplot(df) +\n  geom_point(aes(Cooks, ln.model.1$residuals, color = Fault)) +\n  geom_hline(yintercept = 0, alpha = .2, linetype = \"dashed\") +\n  labs(y = \"Residuals\", title = \"Cooks Plot with Residuals\") +\n  theme_classic()\n\nggplot(df) +\n  geom_point(aes(as.numeric(row.names(df)), Cooks, color = Fault)) +\n  labs(x = \"Indices\", y = \"Cooks\", title = \"Cooks Plot with Date Indices\") +\n  theme_classic()\n```\n\n**Re-run the regression model omitting data where OdoFault==1. Please interpret the results provided by the regression table.**\n\nThe model is much better once the faulty odometer data had been omitted. The intercept is much lower, and the slope of the regression is more reasonable at 21 mpg. In addition, the model test statistics are much better. The slope p-value is very small, significant at the .001 level. The models R2 value also saw a bump up to .34, meaning the regression can explain about 35% of the variance seen in the data.\n\n```{r}\nln.model.2 = lm(Miles~Gallons, data = fuel.data[fuel.data$OdoFault != 1,])\n```\n\n```{r}\nsummary(ln.model.2)\n```\n\n```{r}\nggplot(fuel.data[fuel.data$OdoFault != 1,]) +\n  geom_point(aes(Gallons, Miles), color = \"red\") +\n  geom_line(aes(Gallons, ln.model.2$fitted.values)) +\n  labs(y = \"Miles\", title = \"Residual plot for Miles reressed on Gallons (filtered)\") +\n  geom_hline(yintercept = 0, alpha = .2) +\n theme_classic() \n```\n\n```{r}\nggplot(fuel.data[fuel.data$OdoFault != 1,]) +\n  geom_point(aes(Gallons, ln.model.2$residuals), color =\"red\") +\n  labs(y = \"Residuals\", title = \"Residual plot for Miles reressed on Gallons (filtered)\") +\n  geom_hline(yintercept = 0, alpha = .2) +\n  theme_classic() \n```\n\n**Predict the miles travelled for each of the points where the odometer was not working using the output of the new linear regression model. Plot the predicted miles versus the \"faulty\" miles.**\n\n```{r}\nnew = data.frame(Gallons = fuel.data[fuel.data$OdoFault == 1,3])\nnew$fit = predict.lm(ln.model.2, newdata =  new)\nnew$fault = fuel.data[fuel.data$OdoFault == 1,2]\n```\n\n```{r}\nggplot() +\n  geom_point(data = new, aes(fault, fit)) +\n  ylim(0,300) +\n  labs(x = \"Faulty Miles\", y = \"Predicted 'Corrected' Miles\", title = \"Predicted miles versus the 'faulty' miles\") +\n  theme_classic()\n```\n\n**Using the new linear regression model, what is the MSE for the \"correct\" mileage points? What is the\nMSE for the \"incorrect\" mileage points?**\n\nhe MSE for the first model with faulty data was 4938.7.\nThe MSE for the second model with filtered data was 1020.\n\n```{r}\nanova(ln.model.1)\nanova(ln.model.2)\n```\n\n\n\n\n\n\n\n\n\n\n\n",
    "created" : 1558547479632.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2265052973",
    "id" : "6DBBEB5B",
    "lastKnownWriteTime" : 1556859737,
    "last_content_update" : 1556859737,
    "path" : "~/10 Course Work/10 Spring 2019/TTP 289/Homework/HW_2/TTP289_HW_2.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}